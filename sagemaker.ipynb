{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyzing Amazon Inventory Stock in Image Bins\n",
    "This notebook contains code for training a pytorch model on Amazon Inventory dataset. The dataset contains images of bin ofs items that are sold by amazon on their ecommerce business\n",
    "\n",
    "The script starts by installing and loading the  packages necessary to complete our project. Our project majorly uses `pytorch, torch` and `torchvision`  packages to train and test a deep learning model.\n",
    "We download data from the amazon imagery website.\n",
    "\n",
    "After data download we upload the data to a specified AWS S3 bucket. We then create an estimator that will fetch data from this bucket ,given necessary authentication and fit on the data using an already prepared `train.py` script. \n",
    "\n",
    "We observe  the output of this model fitting to judge the performance of  our model. All this accomplished on AWS Cloud platform using `sagemaker`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "#  Install any packages that you might need\n",
    "!pip install --no-cache-dir smdebug torch pytorch torchvision tqdm split-folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#  Import any packages that you might need\n",
    "import splitfolders\n",
    "from tqdm import tqdm\n",
    "\n",
    "import sagemaker\n",
    "\n",
    "from sagemaker.tuner import CategoricalParameter, ContinuousParameter, HyperparameterTuner\n",
    "from sagemaker.pytorch import PyTorch\n",
    "from sagemaker import get_execution_role\n",
    "from sagemaker.debugger import Rule, DebuggerHookConfig, TensorBoardOutputConfig, CollectionConfig, ProfilerRule, rule_configs\n",
    "from sagemaker.debugger import ProfilerConfig, FrameworkProfile\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation\n",
    "**TODO:** Run the cell below to download the data.\n",
    "\n",
    "The cell below creates a folder called `train_data`, downloads training data and arranges it in subfolders. Each of these subfolders contain images where the number of objects is equal to the name of the folder. For instance, all images in folder `1` has images with 1 object in them. Images are not divided into training, testing or validation sets. If you feel like the number of samples are not enough, you can always download more data (instructions for that can be found [here](https://registry.opendata.aws/amazon-bin-imagery/)). However, we are not acessing you on the accuracy of your final trained model, but how you create your machine learning engineering pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import boto3\n",
    "\n",
    "def download_and_arrange_data():\n",
    "    s3_client = boto3.client('s3')\n",
    "\n",
    "    with open('file_list.json', 'r') as f:\n",
    "        d=json.load(f)\n",
    "\n",
    "    for k, v in d.items():\n",
    "        print(f\"Downloading Images with {k} objects\")\n",
    "        directory=os.path.join('train_data', k)\n",
    "        if not os.path.exists(directory):\n",
    "            os.makedirs(directory)\n",
    "        for file_path in tqdm(v):\n",
    "            file_name=os.path.basename(file_path).split('.')[0]+'.jpg'\n",
    "            s3_client.download_file('aft-vbi-pds', os.path.join('bin-images', file_name),\n",
    "                             os.path.join(directory, file_name))\n",
    "\n",
    "# download_and_arrange_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "\n",
    "Our project uses [Amazom Image Bin Data Set](https://registry.opendata.aws/amazon-bin-imagery/). The dataset contains images of inventory of bins for items that are traded in Amazon e-commerce platform. \n",
    "\n",
    "The official description of the data by the website is as follows;\n",
    "\n",
    "  *The Amazon Bin Image Dataset contains over 500,000 images and metadata from bins of a pod in an operating Amazon Fulfillment Center. The bin images in this dataset are captured as robot units carry pods as part of normal Amazon Fulfillment Center operations.*\n",
    "  \n",
    "  However in our project we will just use some of the data, just about 10,000 images. \n",
    "  \n",
    "  The dataset images are grouped into `folders` with names denoted by numbers 1 up to 5. With the numbers representing the number of items contained in each  of the images respectively.So the `folder` name 1 holds bins images with 1 item, the same goes for folder 2 and so on. \n",
    "  \n",
    "  The downloded `train_data` is split into `train`, `test` and `val` ,each containing data for training, testing and validation respectively [splitfolders package](https://pypi.org/project/split-folders/).\n",
    "  \n",
    "You can find more information about the data [here](https://registry.opendata.aws/amazon-bin-imagery/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Perform any data cleaning or data preprocessing\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#splitfolders.ratio('train_data', output=\"train_data\", seed=1337, ratio=(.6, 0.2,0.2)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "%%capture \n",
    "!aws s3 sync train_data s3://amzn-buckett/\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training\n",
    "\n",
    "For model traing we us `resnet34` model that was proposed to perform best by our benchmark model.The model configuration are specified in the `train.py` script. \n",
    "\n",
    "The architecture is initialiazed as follows; \n",
    "\n",
    "```\n",
    "net = models.__dict__[args.arch]()\n",
    "        \n",
    "in_features = net.fc.in_features\n",
    "new_fc = nn.Linear(in_features,6)\n",
    "net.fc = new_fc\n",
    "model=net\n",
    "\n",
    "```\n",
    "The model names is specified in `args.arch` arguments with `resnet34` set to be the default.See below;\n",
    "\n",
    "```parser.add_argument('--arch', '-a', metavar='ARCH', default='resnet34', choices=model_names, help='model architecture: ' + ' | '.join(model_names) + ' (default: resnet34)')```\n",
    "\n",
    "You can specify the model you want by `model` variable to set your preffered model. The variable stores the names in a dictionary.\n",
    "\n",
    "\n",
    "**Note:** You will need to use the `train.py` script to train your model.\n",
    "\n",
    "**Note:** You will need to use the `train.py` script to train your model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: Declare your model training hyperparameter.\n",
    "#NOTE: You do not need to do hyperparameter tuning. You can use fixed hyperparameter values\n",
    "hyperparameter_ranges = {\n",
    "    \"learning_rate\": ContinuousParameter(0.001, 0.1),\n",
    "    \"batch_size\": CategoricalParameter([32, 64, 128, 256, 512]),\n",
    "}\n",
    "\n",
    "role = sagemaker.get_execution_role()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create your training estimator\n",
    "estimator = PyTorch(\n",
    "    entry_point=\"train.py\",\n",
    "    base_job_name='job-amazon-bins',\n",
    "    role=role,\n",
    "    framework_version=\"1.4.0\",\n",
    "    instance_count=1,\n",
    "    instance_type=\"ml.g4dn.xlarge\",\n",
    "    py_version='py3'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['SM_CHANNEL_TRAINING']='s3://amzn-buckett/'\n",
    "os.environ['SM_MODEL_DIR']='s3://amzn-buckett/model/'\n",
    "os.environ['SM_OUTPUT_DATA_DIR']='s3://amzn-bukett/output/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-01-16 19:29:47 Starting - Starting the training job...\n",
      "2022-01-16 19:30:12 Starting - Launching requested ML instancesProfilerReport-1642361387: InProgress\n",
      "......\n",
      "2022-01-16 19:31:13 Starting - Preparing the instances for training.........\n",
      "2022-01-16 19:32:33 Downloading - Downloading input data..................\n",
      "2022-01-16 19:35:35 Training - Downloading the training image..\u001b[34mbash: cannot set terminal process group (-1): Inappropriate ioctl for device\u001b[0m\n",
      "\u001b[34mbash: no job control in this shell\u001b[0m\n",
      "\u001b[34m2022-01-16 19:35:53,338 sagemaker-containers INFO     Imported framework sagemaker_pytorch_container.training\u001b[0m\n",
      "\u001b[34m2022-01-16 19:35:53,360 sagemaker_pytorch_container.training INFO     Block until all host DNS lookups succeed.\u001b[0m\n",
      "\u001b[34m2022-01-16 19:35:53,363 sagemaker_pytorch_container.training INFO     Invoking user training script.\u001b[0m\n",
      "\u001b[34m2022-01-16 19:35:53,769 sagemaker-containers INFO     Module default_user_module_name does not provide a setup.py. \u001b[0m\n",
      "\u001b[34mGenerating setup.py\u001b[0m\n",
      "\u001b[34m2022-01-16 19:35:53,770 sagemaker-containers INFO     Generating setup.cfg\u001b[0m\n",
      "\u001b[34m2022-01-16 19:35:53,770 sagemaker-containers INFO     Generating MANIFEST.in\u001b[0m\n",
      "\u001b[34m2022-01-16 19:35:53,770 sagemaker-containers INFO     Installing module with the following command:\u001b[0m\n",
      "\u001b[34m/opt/conda/bin/python3.6 -m pip install . \u001b[0m\n",
      "\u001b[34mProcessing /tmp/tmpb9xr92vo/module_dir\u001b[0m\n",
      "\u001b[34mBuilding wheels for collected packages: default-user-module-name\n",
      "  Building wheel for default-user-module-name (setup.py): started\n",
      "  Building wheel for default-user-module-name (setup.py): finished with status 'done'\n",
      "  Created wheel for default-user-module-name: filename=default_user_module_name-1.0.0-py2.py3-none-any.whl size=7637 sha256=b9ac190c4bef1f8d318dd7196c0446d5a7e3a3385faa29dc536724688afd2d64\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-081mjekq/wheels/b0/93/1b/51b95cd0e6eba2a607a16fbf5521a33df22475533f3d78b52d\u001b[0m\n",
      "\u001b[34mSuccessfully built default-user-module-name\u001b[0m\n",
      "\u001b[34mInstalling collected packages: default-user-module-name\u001b[0m\n",
      "\u001b[34mSuccessfully installed default-user-module-name-1.0.0\u001b[0m\n",
      "\u001b[34m2022-01-16 19:35:56,048 sagemaker-containers INFO     Invoking user script\u001b[0m\n",
      "\u001b[34mTraining Env:\u001b[0m\n",
      "\u001b[34m{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {\n",
      "        \"training\": \"/opt/ml/input/data/training\"\n",
      "    },\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"framework_module\": \"sagemaker_pytorch_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"hyperparameters\": {},\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"training\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"is_master\": true,\n",
      "    \"job_name\": \"job-amazon-bins-2022-01-16-19-29-47-147\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://sagemaker-us-east-1-953953830980/job-amazon-bins-2022-01-16-19-29-47-147/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"train\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 4,\n",
      "    \"num_gpus\": 1,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"train.py\"\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[34mEnvironment variables:\u001b[0m\n",
      "\u001b[34mSM_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[34mSM_HPS={}\u001b[0m\n",
      "\u001b[34mSM_USER_ENTRY_POINT=train.py\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
      "\u001b[34mSM_RESOURCE_CONFIG={\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[34mSM_INPUT_DATA_CONFIG={\"training\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[34mSM_CHANNELS=[\"training\"]\u001b[0m\n",
      "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34mSM_MODULE_NAME=train\u001b[0m\n",
      "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_MODULE=sagemaker_pytorch_container.training:main\u001b[0m\n",
      "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[34mSM_NUM_CPUS=4\u001b[0m\n",
      "\u001b[34mSM_NUM_GPUS=1\u001b[0m\n",
      "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_MODULE_DIR=s3://sagemaker-us-east-1-953953830980/job-amazon-bins-2022-01-16-19-29-47-147/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"training\":\"/opt/ml/input/data/training\"},\"current_host\":\"algo-1\",\"framework_module\":\"sagemaker_pytorch_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"training\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"job-amazon-bins-2022-01-16-19-29-47-147\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-east-1-953953830980/job-amazon-bins-2022-01-16-19-29-47-147/source/sourcedir.tar.gz\",\"module_name\":\"train\",\"network_interface_name\":\"eth0\",\"num_cpus\":4,\"num_gpus\":1,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"train.py\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ARGS=[]\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TRAINING=/opt/ml/input/data/training\u001b[0m\n",
      "\u001b[34mPYTHONPATH=/opt/ml/code:/opt/conda/bin:/opt/conda/lib/python36.zip:/opt/conda/lib/python3.6:/opt/conda/lib/python3.6/lib-dynload:/opt/conda/lib/python3.6/site-packages\u001b[0m\n",
      "\u001b[34mInvoking script with the following command:\u001b[0m\n",
      "\u001b[34m/opt/conda/bin/python3.6 train.py\u001b[0m\n",
      "\u001b[34mNamespace(arch='resnet34', batch_size=128, data='/opt/ml/input/data/training', epochs=40, evaluate=False, lastlayer=False, learning_rate=0.1, lrd=10, model_dir='/opt/ml/model', momentum=0.9, output_dir='/opt/ml/output/data', print_freq=10, resume='', save_model_id=1, start_epoch=0, weight_decay=0.0001, workers=8)\u001b[0m\n",
      "\u001b[34mHyperparameters are LR: 0.1, Batch Size: 128\u001b[0m\n",
      "\u001b[34mData Paths: /opt/ml/input/data/training\u001b[0m\n",
      "\u001b[34m=> creating model 'resnet34'\u001b[0m\n",
      "\u001b[34mStarting Model Training\u001b[0m\n",
      "\u001b[34mEpoch: 0\u001b[0m\n",
      "\u001b[34m[2022-01-16 19:35:59.063 algo-1:44 INFO json_config.py:90] Creating hook from json_config at /opt/ml/input/config/debughookconfig.json.\u001b[0m\n",
      "\u001b[34m[2022-01-16 19:35:59.064 algo-1:44 INFO hook.py:192] tensorboard_dir has not been set for the hook. SMDebug will not be exporting tensorboard summaries.\u001b[0m\n",
      "\u001b[34m[2022-01-16 19:35:59.064 algo-1:44 INFO hook.py:237] Saving to /opt/ml/output/tensors\u001b[0m\n",
      "\u001b[34m[2022-01-16 19:35:59.064 algo-1:44 INFO state_store.py:67] The checkpoint config file /opt/ml/input/config/checkpointconfig.json does not exist.\u001b[0m\n",
      "\u001b[34m[2022-01-16 19:35:59.081 algo-1:44 INFO hook.py:382] Monitoring the collections: losses\u001b[0m\n",
      "\u001b[34m[2022-01-16 19:35:59.082 algo-1:44 INFO hook.py:443] Hook is writing from the hook with pid: 44\u001b[0m\n",
      "\n",
      "2022-01-16 19:36:14 Training - Training image download completed. Training in progress.\u001b[34mtrain loss: 4627.0000, acc: 27.0000, best loss: 1000000.0000\u001b[0m\n",
      "\u001b[34mvalid loss: 5131.0000, acc: 31.0000, best loss: 5131.0000\u001b[0m\n",
      "\u001b[34mTesting Model\u001b[0m\n",
      "\u001b[34mTesting Loss: 5146.0\u001b[0m\n",
      "\u001b[34mTesting Accuracy: 31.0\u001b[0m\n",
      "\u001b[34mSaving Model\u001b[0m\n",
      "\u001b[34m2022-01-16 19:53:43,076 sagemaker-containers INFO     Reporting training SUCCESS\u001b[0m\n",
      "\n",
      "2022-01-16 19:54:00 Uploading - Uploading generated training model\n",
      "2022-01-16 19:54:20 Completed - Training job completed\n",
      "ProfilerReport-1642361387: IssuesFound\n",
      "Training seconds: 1298\n",
      "Billable seconds: 1298\n"
     ]
    }
   ],
   "source": [
    "estimator.fit({\"training\": \"s3://amzn-buckett/\"}, wait=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standout Suggestions\n",
    "You do not need to perform the tasks below to finish your project. However, you can attempt these tasks to turn your project into a more advanced portfolio piece."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter Tuning\n",
    "**TODO:** Here you can perform hyperparameter tuning to increase the performance of your model. You are encouraged to \n",
    "- tune as many hyperparameters as you can to get the best performance from your model\n",
    "- explain why you chose to tune those particular hyperparameters and the ranges.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: Create your hyperparameter search space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: Create your training estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Fit your estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Find the best hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Profiling and Debugging\n",
    "**TODO:** Use model debugging and profiling to better monitor and debug your model training job."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Set up debugging and profiling rules and hooks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Create and fit an estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Plot a debugging output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODO**: Is there some anomalous behaviour in your debugging output? If so, what is the error and how will you fix it?  \n",
    "**TODO**: If not, suppose there was an error. What would that error look like and how would you have fixed it?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Display the profiler output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Deploying and Querying\n",
    "**TODO:** Can you deploy your model to an endpoint and then query that endpoint to get a result?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Deploy your model to an endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Run an prediction on the endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Remember to shutdown/delete your endpoint once your work is done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cheaper Training and Cost Analysis\n",
    "**TODO:** Can you perform a cost analysis of your system and then use spot instances to lessen your model training cost?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Cost Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Train your model using a spot instance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi-Instance Training\n",
    "**TODO:** Can you train your model on multiple instances?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Train your model on Multiple Instances"
   ]
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
